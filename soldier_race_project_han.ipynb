{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfUdHCfe1b6v"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "heading_collapsed": true,
    "id": "CvFxPmf41b6y"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "WZUMKNQY1b6y"
   },
   "source": [
    "In this project, you must apply EDA processes for the development of predictive models. Handling outliers, domain knowledge and feature engineering will be challenges.\n",
    "\n",
    "Also, this project aims to improve your ability to implement algorithms for Multi-Class Classification. Thus, you will have the opportunity to implement many algorithms commonly used for Multi-Class Classification problems.\n",
    "\n",
    "Before diving into the project, please take a look at the determines and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "heading_collapsed": true,
    "id": "laCRtJs51b6z"
   },
   "source": [
    "# Determines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "iixh9Bej1b6z"
   },
   "source": [
    "The 2012 US Army Anthropometric Survey (ANSUR II) was executed by the Natick Soldier Research, Development and Engineering Center (NSRDEC) from October 2010 to April 2012 and is comprised of personnel representing the total US Army force to include the US Army Active Duty, Reserves, and National Guard. In addition to the anthropometric and demographic data described below, the ANSUR II database also consists of 3D whole body, foot, and head scans of Soldier participants. These 3D data are not publicly available out of respect for the privacy of ANSUR II participants. The data from this survey are used for a wide range of equipment design, sizing, and tariffing applications within the military and has many potential commercial, industrial, and academic applications.\n",
    "\n",
    "The ANSUR II working databases contain 93 anthropometric measurements which were directly measured, and 15 demographic/administrative variables explained below. The ANSUR II Male working database contains a total sample of 4,082 subjects. The ANSUR II Female working database contains a total sample of 1,986 subjects.\n",
    "\n",
    "\n",
    "DATA DICT:\n",
    "https://data.world/datamil/ansur-ii-data-dictionary/workspace/file?filename=ANSUR+II+Databases+Overview.pdf\n",
    "\n",
    "---\n",
    "\n",
    "To achieve high prediction success, you must understand the data well and develop different approaches that can affect the dependent variable.\n",
    "\n",
    "Firstly, try to understand the dataset column by column using pandas module. Do research within the scope of domain (body scales, and race characteristics) knowledge on the internet to get to know the data set in the fastest way. \n",
    "\n",
    "You will implement ***Logistic Regression, Support Vector Machine, XGBoost, Random Forest*** algorithms. Also, evaluate the success of your models with appropriate performance metrics.\n",
    "\n",
    "At the end of the project, choose the most successful model and try to enhance the scores with ***SMOTE*** make it ready to deploy. Furthermore, use ***SHAP*** to explain how the best model you choose works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "heading_collapsed": true,
    "id": "P2UckCvP1b60"
   },
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "gCVDEsGB1b60"
   },
   "source": [
    "#### 1. Exploratory Data Analysis (EDA)\n",
    "- Import Libraries, Load Dataset, Exploring Data\n",
    "\n",
    "    *i. Import Libraries*\n",
    "    \n",
    "    *ii. Ingest Data *\n",
    "    \n",
    "    *iii. Explore Data*\n",
    "    \n",
    "    *iv. Outlier Detection*\n",
    "    \n",
    "    *v.  Drop unnecessary features*\n",
    "\n",
    "#### 2. Data Preprocessing\n",
    "- Scale (if needed)\n",
    "- Separete the data frame for evaluation purposes\n",
    "\n",
    "#### 3. Multi-class Classification\n",
    "- Import libraries\n",
    "- Implement SVM Classifer\n",
    "- Implement Decision Tree Classifier\n",
    "- Implement Random Forest Classifer\n",
    "- Implement XGBoost Classifer\n",
    "- Compare The Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Y5-Kay1Eqvdj"
   },
   "source": [
    "# EDA\n",
    "- Drop unnecessary colums\n",
    "- Drop DODRace class if value count below 500 (we assume that our data model can't learn if it is below 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "K7UZHtvu1b62"
   },
   "source": [
    "## Import Libraries\n",
    "Besides Numpy and Pandas, you need to import the necessary modules for data visualization, data preprocessing, Model building and tuning.\n",
    "\n",
    "*Note: Check out the course materials.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OqnRjwHB1b64"
   },
   "outputs": [],
   "source": [
    "# Gerekli paketleri yükleme işlemi\n",
    "import pandas as pd              # Veri çerçevelerini yüklemek ve manipüle etmek için kullanılır.\n",
    "import numpy as np               # Matrisler ve diğer sayısal veriler için kullanılır.\n",
    "import matplotlib.pyplot as plt  # Veri görselleştirme için kullanılır.\n",
    "import seaborn as sns            # Veri görselleştirme için kullanılır ve matplotlib'in üzerine kuruludur.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams[\"figure.figsize\"] = (7,4)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "# Logistic Regression için gerekli paketleri yükleyin\n",
    "from sklearn.linear_model import LogisticRegression  # Lojistik Regresyon modeli için kullanılır\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # Model performansını değerlendirmek için kullanılır\n",
    "from sklearn.model_selection import train_test_split  # Verileri eğitim ve test setlerine ayırmak için kullanılır\n",
    "\n",
    "# Support Vector Machine için gerekli paketleri yükleyin\n",
    "from sklearn.svm import SVC  # Destek Vektör Makineleri modeli için kullanılır\n",
    "#!pip install xgboost==1.7.3\n",
    "# XGBoost için gerekli paketleri yükleyin\n",
    "import xgboost as xgb  # XGBoost modeli için kullanılır\n",
    "\n",
    "# Random Forest için gerekli paketleri yükleyin\n",
    "from sklearn.ensemble import RandomForestClassifier  # Rastgele Orman modeli için kullanılır"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "C5lJeTBu1b65"
   },
   "source": [
    "## Ingest Data from links below and make a dataframe\n",
    "- Soldiers Male : https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr\n",
    "- Soldiers Female : https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "hidden": true,
    "id": "tG5BsWraqX_y",
    "outputId": "a6e730fa-6848-4cfc-becb-284fc8cc99e5"
   },
   "outputs": [],
   "source": [
    "# Veri kümesini yükleyin\n",
    "male = pd.read_csv('ansur_male.csv',encoding='latin-1')\n",
    "female = pd.read_csv('ansur_female.csv',encoding='latin-1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "TMjCTEG51b67"
   },
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "hidden": true,
    "id": "SnlGRPWbrNAj",
    "outputId": "29ed8227-1450-4213-e9d1-a2953167d415"
   },
   "outputs": [],
   "source": [
    "male.head(1)\n",
    "# male içerisine bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female.head(1)\n",
    "#female içerisine bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = female.rename(columns={'SubjectId': 'subjectid'})\n",
    "# aynı dataframede birleştirmek için ordak id sütun isimlerini eşitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.concat([male,female])\n",
    "#male ve female veri setlerini birleştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Ethnicity', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "CS5-GZy0sl4s"
   },
   "source": [
    "# DATA Preprocessing\n",
    "- In this step we divide our data to X(Features) and y(Target) then ,\n",
    "- To train and evaluation purposes we create train and test sets,\n",
    "- Lastly, scale our data if features not in same scale. Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Şimdi Veri Kümesinde; \"SubjectNumericRace\" ve \"DODRace\" sütunları\n",
    "\n",
    "**SubjectNumericRace**: bir deneğin kendi bildirdiği ırkını veya yarışlarını gösteren tek veya çok basamaklı bir kod (görüşme yoluyla doğrulanmıştır). 1 = Beyaz, 2 = Siyah, 3 = Hispanik, 4 = Asyalı, 5 = Kızılderili, 6 = Pasifik Adalı, 8 = Diğer\n",
    "\n",
    "**DODRace**: Savunma Bakanlığı Yarışı; birden fazla yarış seçmenin bir seçenek olmadığı durumlarda, bir deneğin kendi bildirdiği tercih ettiği tek yarışı gösteren tek bir rakam. Bu değişkenin, Savunma İnsan Gücü Veri Merkezi demografik verileriyle karşılaştırılabilir olması amaçlanmıştır. 1 = Beyaz, 2 = Siyah, 3 = Hispanik, 4 = Asyalı, 5 = Kızılderili, 6 = Pasifik Adalı, 8 = Diğer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"DODRace\",\"SubjectNumericRace\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"SubjectNumericRace\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!!!Drop DODRace class if value count below 500 (we assume that our data model can't learn if it is below 500)\n",
    "if 'DODRace' in dataframe.columns:\n",
    "    value_counts = dataframe['DODRace'].value_counts()\n",
    "    for index, count in value_counts.items():\n",
    "        if count < 500:\n",
    "            dataframe = dataframe[dataframe['DODRace'] != index]\n",
    "    if 'DODRace' in dataframe.columns:\n",
    "        dataframe = dataframe.drop('DODRace', axis=1)\n",
    "yada\n",
    "df.DODRace.value_counts(dropna = False)\n",
    "df = df[df[\"DODRace\"].isin([1,2,3])]\n",
    "df.DODRace.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fr2wgpvk1b7B"
   },
   "outputs": [],
   "source": [
    "df.DODRace.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"DODRace\"].isin([1,2,3])]\n",
    "df.DODRace.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude=[np.number]).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in df.select_dtypes(exclude=[np.number]).columns:\n",
    "    print(f\"{columns} has {df[columns].nunique()} unique value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Component\"])[\"DODRace\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Component\",\"Branch\"])[\"DODRace\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list_nonnumeric = [\"Date\", \"Installation\", \"Component\",\"PrimaryMOS\"]\n",
    "df.drop(drop_list_nonnumeric, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"subjectid\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.corr()\n",
    "\n",
    "count = \"done\"\n",
    "feature =[]\n",
    "collinear=[]\n",
    "for col in df_temp.columns:\n",
    "    for i in df_temp.index:\n",
    "        if (df_temp[col][i]> .9 and df_temp[col][i] < 1) or (df_temp[col][i]< -.9 and df_temp[col][i] > -1) :\n",
    "                feature.append(col)\n",
    "                collinear.append(i)\n",
    "                # print(f\"multicolinearity alert in between {col} - {i}\")\n",
    "print(\"Number of strong corelated features:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = pd.DataFrame([feature, collinear], index=[\"feature\",\"collinear\"]).T\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col.value_counts(\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DODRace\"] = df.DODRace.map({1 : \"White\", 2 : \"Black\", 3 : \"Hispanic\"})\n",
    "df.DODRace.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(\"DODRace\",axis=1)\n",
    "X = pd.get_dummies(data=X,drop_first=True)\n",
    "y= df.DODRace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6, stratify =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zfi_NOw0s2fM"
   },
   "source": [
    "# Modelling\n",
    "- Fit the model with train dataset\n",
    "- Get predict from vanilla model on both train and test sets to examine if there is over/underfitting   \n",
    "- Apply GridseachCV for both hyperparemeter tuning and sanity test of our model.\n",
    "- Use hyperparameters that you find from gridsearch and make final prediction and evaluate the result according to chosen metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "N1cviBuh1b7C"
   },
   "source": [
    "## 1. Logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "0rSJ5hxp1b7C"
   },
   "source": [
    "### Vanilla Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbKDDck012BS"
   },
   "outputs": [],
   "source": [
    "print(y.value_counts(normalize=True))\n",
    "print()\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print()\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "operations = [(\"scaler\", StandardScaler()), (\"logistic\", LogisticRegression())]\n",
    "\n",
    "pipe_model = Pipeline(steps=operations)\n",
    "\n",
    "pipe_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pipe_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test_Set\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(pipe_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "lPelWxsU1b7C"
   },
   "source": [
    "### Logistic Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = make_scorer(f1_score, average=\"weighted\")\n",
    "model = LogisticRegression(class_weight='balanced',max_iter=10000,random_state=6)\n",
    "scores = cross_val_score(model, X_train, y_train, cv = 5, scoring = f1score, n_jobs = -1)\n",
    "print([round(i, 4) for i in scores], \"\\n\")\n",
    "print(f\" f1score : %{scores.mean()*100:.2f}, std : %{scores.std()*100:.3f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "f1_Hispanic =  make_scorer(f1_score, average=None, labels=[\"Hispanic\"] )\n",
    "param_grid = { \"class_weight\" : [\"balanced\", None],\n",
    "               'penalty': [\"l1\",\"l2\"],\n",
    "               'solver' : ['saga','lbfgs'],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced',max_iter=10000,random_state=6)\n",
    "log_model_grid = GridSearchCV(model, param_grid, verbose=1, scoring=f1_Hispanic, refit=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, roc_auc_score, roc_curve,\\\n",
    "                            average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(5,5)):\n",
    "    y_score = clf.decision_function(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(log_model_grid, X_test, y_test, n_classes=3, figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "GM0PL5eZ1b7E"
   },
   "source": [
    "## 2. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "P3j_Xk1L1b7E"
   },
   "source": [
    "### Vanilla SVC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pro8T6CM19vX"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(class_weight=\"balanced\")\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"test scores\",\"\\n--------------\")\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_train)\n",
    "\n",
    "print(\"train scores\",\"\\n--------------\")\n",
    "\n",
    "\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.linspace(200,400,5),\n",
    "              'decision_function_shape' : ['ovr','ovo'],\n",
    "              'gamma': [\"scale\", \"auto\", 1,0.1,0.01],\n",
    "              'kernel': ['rbf'],\n",
    "              'class_weight':[\"balanced\",None]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "28y9nWxG1b7E"
   },
   "source": [
    "###  SVC Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(class_weight=\"balanced\")\n",
    "svm_model_grid = GridSearchCV(model, param_grid, verbose=1, scoring=f1_Hispanic, refit=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model_grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(svm_model_grid, X_test, y_test, n_classes=3, figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dFocgCo1-0Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bDX_iLIls74C"
   },
   "source": [
    "## 3. RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "qaTzrT6P1b7G"
   },
   "source": [
    "### Vanilla RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvtqL0Qg2CKf"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mod = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_mod.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_mod.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MkLAZ_M41b7G"
   },
   "source": [
    "### RF Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[400,500],\n",
    "             'criterion': [\"gini\",\"entropy\"],\n",
    "             'max_depth':[10,12,14,16],\n",
    "             'min_samples_split':[18,20,22],\n",
    "             'class_weight': ['balanced',None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_grid_model = GridSearchCV(rf_model, param_grid, verbose=1, scoring=f1_Hispanic, refit=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpmPr3202EbD"
   },
   "outputs": [],
   "source": [
    "y_pred = rf_grid_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc_for_tree(clf, X_test, y_test, n_classes, figsize=(5,5)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    #Fonksiyon, clf sınıflandırıcısı tarafından tahmin edilen olasılıkları (y_score) kullanarak,\n",
    "    #her bir sınıf için FPR (False Positive Rate), TPR (True Positive Rate) ve AUC (Area Under the Curve)\n",
    "    #değerlerini hesaplar. Daha sonra, bu değerleri kullanarak ROC eğrisini çizer ve her bir sınıf için \n",
    "    #eğri altındaki alanı hesaplar ve grafik üzerinde gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc_for_tree(rf_grid_model, X_test, y_test, n_classes=3, figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "PvcPc4V81b7H"
   },
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MuxxUFoW1b7H"
   },
   "source": [
    "### Vanilla XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nfi1aa152HbR"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# y_train ve y_test etiketlerini sayısal değerlere dönüştürme\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "classes_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "comp = pd.DataFrame(classes_weights)\n",
    "comp[\"label\"] = pd.Series(y_train).reset_index(drop=True)\n",
    "comp.groupby(\"label\")[0].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "p3gH5QvE1b7I"
   },
   "source": [
    "### XGBoost Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72E3Cmnm2KOE"
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\":[100, 300],\n",
    "              'max_depth':[3,5,6],\n",
    "              \"learning_rate\": [0.1, 0.3],\n",
    "              \"subsample\":[0.5, 1],\n",
    "              \"colsample_bytree\":[0.5, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_grid_model = GridSearchCV(xgb_model, param_grid, \n",
    "                              scoring=f1_Hispanic, n_jobs = -1,\n",
    "                              refit=True, verbose = 1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_grid_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc_for_tree(xgb_grid_model, X_test, y_test, n_classes=3, figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DbXAmOPVDatl"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WvWpInu21b7L"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "xg2k1ScZ1b7L"
   },
   "source": [
    "# SMOTE\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9Rqk02x61b7L"
   },
   "source": [
    "##  Smote implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XTN4iO7i1b7L"
   },
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Cv5155AN1b7L"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aoKU_HZR1b7M"
   },
   "source": [
    "## SVC Over/Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkNSgnut2Z6N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1hBIqmFL1b7O"
   },
   "source": [
    "## Xgboost Over/ Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12AItu1M2ds0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "T1pPLjpA1b7P"
   },
   "source": [
    "- Evaluation metrics \n",
    "https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Me3OZtQF1b7P",
    "outputId": "6280fddb-b392-40c1-87d3-57d242ce2528"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "P74oLhzK1b7P",
    "outputId": "350b8e9d-dd72-4566-8b11-10526699cd94"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "AVnS0UKO1b7P"
   },
   "source": [
    "#  SHAP\n",
    "\n",
    "https://towardsdatascience.com/shap-explain-any-machine-learning-model-in-python-24207127cad7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "-vB4oVMU1b7P",
    "outputId": "f9c79861-e5c2-4a60-a2f7-02e6c52a82f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ryW4sFrT1b7P"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(log_model,X_train)\n",
    "start_index = 203\n",
    "end_index = 204\n",
    "shap_values = explainer.shap_values(X_test[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "eTTPiHfB1b7Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "IVG77ukO1b7Q",
    "outputId": "96901cda-3c6c-4fe4-a36b-eb43b08cc86e"
   },
   "outputs": [],
   "source": [
    "print(shap_values[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Ea2YZzkQ1b7Q"
   },
   "outputs": [],
   "source": [
    "# %% >> Visualize local predictions\n",
    "shap.initjs()\n",
    "# Force plot\n",
    "prediction = log_model.predict(X_test[start_index:end_index])[0]\n",
    "print(f\"The log_model predicted: {prediction}\")\n",
    "shap.force_plot(explainer.expected_value[1],\n",
    "                shap_values[1],\n",
    "                X_test[start_index:end_index], # for values\n",
    "                feature_names= X.columns,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "DscXral61b7Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train,max_display=300,feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "9hxUcvZG1b7J"
   },
   "source": [
    "# Before the Deployment \n",
    "- Choose the model that works best based on your chosen metric\n",
    "- For final step, fit the best model with whole dataset to get better performance.\n",
    "- And your model ready to deploy, dump your model and scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UOn_G0n2N2Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "g8_x-BiN1b7Q"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K7UZHtvu1b62",
    "C5lJeTBu1b65",
    "TMjCTEG51b67",
    "CS5-GZy0sl4s",
    "zfi_NOw0s2fM",
    "p3gH5QvE1b7I",
    "9hxUcvZG1b7J",
    "9Rqk02x61b7L",
    "aoKU_HZR1b7M",
    "1hBIqmFL1b7O",
    "AVnS0UKO1b7P"
   ],
   "name": "soldier_race_project_students.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "interpreter": {
   "hash": "e4e90950cb561445fc7289d5187c528b28750a487d008a70b474c773afaf79b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 527,
   "position": {
    "height": "40px",
    "left": "1034px",
    "right": "20px",
    "top": "185px",
    "width": "661px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
